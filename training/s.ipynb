{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as pl\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 11:44:53.168311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.183666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.183806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.185092: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-04 11:44:53.185379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.185493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.185587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.567232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.567365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.567459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-04 11:44:53.567542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2048 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 2GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=2048)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data for Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "falling_paths = [\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall2.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall3.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall4.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall1.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall5.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall6.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall7.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall8.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall9.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall10.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall11.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall12.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall13.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall14.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_moving/resized_logitech-fall15.mp4\"\n",
    "                 ]\n",
    "\n",
    "default_paths = [\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default1.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default2.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default3.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default4.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default5.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default6.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default7.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default8.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default9.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default10.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default11.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default12.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default13.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default14.mp4\",\n",
    "                 \"./../datasets/vids/splitted/new_still/resized_logitech-default15.mp4\"\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing code, returns frame (num_frames, 224,224,3) and frame_diffs (num_frames, 224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to apply the same random transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_videos(video_paths, label):\n",
    "    frames = []\n",
    "    frame_diffs = []\n",
    "    labels = []\n",
    "    \n",
    "    for path in video_paths:\n",
    "        video_cap = cv2.VideoCapture(path)\n",
    "        \n",
    "        prev_gray_frame = None\n",
    "        \n",
    "        while video_cap.isOpened():\n",
    "            ret, frame = video_cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Resize and convert frame to RGB\n",
    "            frame_resized = cv2.resize(frame, (224, 224))\n",
    "            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Convert frame to grayscale\n",
    "            gray_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            if prev_gray_frame is None:\n",
    "                frame_diff = np.zeros_like(gray_frame, dtype=np.float32)\n",
    "            else:\n",
    "                frame_diff = cv2.absdiff(prev_gray_frame, gray_frame)\n",
    "                # frame_diff = cv2.absdiff(prev_gray_frame, gray_frame) / 255.0\n",
    "            \n",
    "            prev_gray_frame = gray_frame\n",
    "            \n",
    "            frames.append(frame_rgb)\n",
    "            frame_diffs.append(frame_diff)\n",
    "            labels.append(label)  # 0 for still, 1 for moving\n",
    "            \n",
    "            \n",
    "        video_cap.release()\n",
    "\n",
    "    return np.array(frames), np.array(frame_diffs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping to 224 x 224 x 4 for the convolutional model\n",
    "def combine_frames_and_diffs(frames, frame_diffs):\n",
    "    # frame_diffs dimension\n",
    "    # print(frame_diffs.shape)\n",
    "    frame_diffs_expanded = np.expand_dims(frame_diffs, axis=-1) # Add an extra dimension\n",
    "    # frame_diffs_expanded dimension\n",
    "    # print(frame_diffs_expanded.shape)\n",
    "    combined_input = np.concatenate([frames, frame_diffs_expanded], axis=-1) # Concatenate along the last axis\n",
    "    # combined_input dimension\n",
    "    # print(combined_input.shape)\n",
    "    \n",
    "    # Visualize the difference\n",
    "    # cv2.imwrite('img_still.png', combined_input[10])\n",
    "    return combined_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [135. 135. 132.   0.]\n",
      "   ...\n",
      "   [119. 121. 116.   0.]\n",
      "   [120. 122. 117.   0.]\n",
      "   [120. 122. 117.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[186. 182. 174.   0.]\n",
      "   [195. 191. 183.   0.]\n",
      "   [198. 194. 186.   0.]\n",
      "   ...\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]]\n",
      "\n",
      "  [[191. 187. 179.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]\n",
      "\n",
      "  [[195. 191. 183.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]]\n",
      "\n",
      "\n",
      " [[[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [135. 135. 132.   0.]\n",
      "   ...\n",
      "   [119. 121. 116.   0.]\n",
      "   [120. 122. 117.   0.]\n",
      "   [120. 122. 117.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[186. 182. 174.   0.]\n",
      "   [195. 191. 183.   0.]\n",
      "   [198. 194. 186.   0.]\n",
      "   ...\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]]\n",
      "\n",
      "  [[191. 187. 179.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]\n",
      "\n",
      "  [[195. 191. 183.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]]\n",
      "\n",
      "\n",
      " [[[125. 125. 122.   8.]\n",
      "   [128. 128. 125.   5.]\n",
      "   [131. 131. 128.   2.]\n",
      "   ...\n",
      "   [121. 126. 120.   6.]\n",
      "   [122. 127. 121.   7.]\n",
      "   [122. 127. 121.   5.]]\n",
      "\n",
      "  [[142. 142. 139.   9.]\n",
      "   [151. 151. 148.  18.]\n",
      "   [149. 149. 146.  16.]\n",
      "   ...\n",
      "   [121. 126. 120.   6.]\n",
      "   [122. 127. 121.   5.]\n",
      "   [122. 127. 121.   5.]]\n",
      "\n",
      "  [[187. 187. 184.  54.]\n",
      "   [220. 220. 217.  87.]\n",
      "   [224. 224. 221.  89.]\n",
      "   ...\n",
      "   [121. 126. 120.   4.]\n",
      "   [122. 127. 121.   4.]\n",
      "   [122. 127. 121.   4.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[209. 205. 197.  23.]\n",
      "   [213. 209. 201.  18.]\n",
      "   [217. 213. 205.  19.]\n",
      "   ...\n",
      "   [145. 141. 133.   1.]\n",
      "   [145. 141. 133.   1.]\n",
      "   [145. 141. 133.   1.]]\n",
      "\n",
      "  [[216. 212. 204.  25.]\n",
      "   [219. 215. 207.  20.]\n",
      "   [221. 217. 209.  19.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]\n",
      "\n",
      "  [[220. 216. 208.  25.]\n",
      "   [221. 217. 209.  22.]\n",
      "   [223. 219. 211.  21.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 79.  78.  83.  14.]\n",
      "   [ 79.  78.  83.  15.]\n",
      "   [ 78.  77.  82.  15.]\n",
      "   ...\n",
      "   [252. 236. 253.   8.]\n",
      "   [251. 235. 250.  10.]\n",
      "   [250. 234. 249.  11.]]\n",
      "\n",
      "  [[ 79.  78.  83.  13.]\n",
      "   [ 79.  78.  83.  14.]\n",
      "   [ 78.  77.  82.  14.]\n",
      "   ...\n",
      "   [252. 236. 253.   8.]\n",
      "   [251. 235. 250.  10.]\n",
      "   [250. 234. 249.  11.]]\n",
      "\n",
      "  [[ 80.  79.  84.  15.]\n",
      "   [ 80.  79.  84.  16.]\n",
      "   [ 79.  78.  83.  16.]\n",
      "   ...\n",
      "   [252. 235. 255.   9.]\n",
      "   [251. 235. 252.   9.]\n",
      "   [250. 234. 251.  10.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83.  82.  87.  54.]\n",
      "   [ 82.  81.  86.  53.]\n",
      "   [ 81.  80.  85.  50.]\n",
      "   ...\n",
      "   [232. 248. 246.   2.]\n",
      "   [228. 246. 245.   5.]\n",
      "   [226. 244. 243.  12.]]\n",
      "\n",
      "  [[ 82.  81.  86.  54.]\n",
      "   [ 81.  80.  85.  53.]\n",
      "   [ 80.  79.  84.  49.]\n",
      "   ...\n",
      "   [231. 247. 245.   2.]\n",
      "   [224. 245. 243.  11.]\n",
      "   [223. 244. 242.  13.]]\n",
      "\n",
      "  [[ 81.  80.  85.  54.]\n",
      "   [ 80.  79.  84.  51.]\n",
      "   [ 82.  81.  86.  46.]\n",
      "   ...\n",
      "   [230. 246. 244.   5.]\n",
      "   [224. 245. 243.  12.]\n",
      "   [223. 244. 242.  13.]]]\n",
      "\n",
      "\n",
      " [[[ 79.  78.  83.   0.]\n",
      "   [ 79.  78.  83.   0.]\n",
      "   [ 78.  77.  82.   0.]\n",
      "   ...\n",
      "   [252. 236. 253.   0.]\n",
      "   [251. 235. 250.   0.]\n",
      "   [250. 234. 249.   0.]]\n",
      "\n",
      "  [[ 79.  78.  83.   0.]\n",
      "   [ 79.  78.  83.   0.]\n",
      "   [ 78.  77.  82.   0.]\n",
      "   ...\n",
      "   [252. 236. 253.   0.]\n",
      "   [251. 235. 250.   0.]\n",
      "   [250. 234. 249.   0.]]\n",
      "\n",
      "  [[ 80.  79.  84.   0.]\n",
      "   [ 80.  79.  84.   0.]\n",
      "   [ 79.  78.  83.   0.]\n",
      "   ...\n",
      "   [252. 235. 255.   0.]\n",
      "   [251. 235. 252.   0.]\n",
      "   [250. 234. 251.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83.  82.  87.   0.]\n",
      "   [ 82.  81.  86.   0.]\n",
      "   [ 81.  80.  85.   0.]\n",
      "   ...\n",
      "   [232. 248. 246.   0.]\n",
      "   [228. 246. 245.   0.]\n",
      "   [226. 244. 243.   0.]]\n",
      "\n",
      "  [[ 82.  81.  86.   0.]\n",
      "   [ 81.  80.  85.   0.]\n",
      "   [ 80.  79.  84.   0.]\n",
      "   ...\n",
      "   [231. 247. 245.   0.]\n",
      "   [224. 245. 243.   0.]\n",
      "   [223. 244. 242.   0.]]\n",
      "\n",
      "  [[ 81.  80.  85.   0.]\n",
      "   [ 80.  79.  84.   0.]\n",
      "   [ 82.  81.  86.   0.]\n",
      "   ...\n",
      "   [230. 246. 244.   0.]\n",
      "   [224. 245. 243.   0.]\n",
      "   [223. 244. 242.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 81.  80.  85.   2.]\n",
      "   [ 81.  80.  85.   2.]\n",
      "   [ 80.  79.  84.   2.]\n",
      "   ...\n",
      "   [239. 221. 255.  13.]\n",
      "   [239. 221. 255.  11.]\n",
      "   [241. 223. 255.   8.]]\n",
      "\n",
      "  [[ 83.  82.  87.   4.]\n",
      "   [ 82.  81.  86.   3.]\n",
      "   [ 81.  80.  85.   3.]\n",
      "   ...\n",
      "   [238. 220. 255.  14.]\n",
      "   [239. 221. 255.  11.]\n",
      "   [239. 221. 255.  10.]]\n",
      "\n",
      "  [[ 83.  82.  87.   3.]\n",
      "   [ 83.  82.  87.   3.]\n",
      "   [ 82.  81.  86.   3.]\n",
      "   ...\n",
      "   [238. 220. 255.  13.]\n",
      "   [238. 220. 255.  13.]\n",
      "   [239. 221. 255.  11.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[148. 142. 149.  62.]\n",
      "   [148. 142. 149.  63.]\n",
      "   [148. 142. 149.  64.]\n",
      "   ...\n",
      "   [251. 251. 251.   8.]\n",
      "   [251. 251. 251.  10.]\n",
      "   [251. 251. 251.  12.]]\n",
      "\n",
      "  [[150. 144. 151.  65.]\n",
      "   [150. 144. 151.  66.]\n",
      "   [150. 144. 151.  67.]\n",
      "   ...\n",
      "   [251. 251. 251.   9.]\n",
      "   [251. 251. 251.  13.]\n",
      "   [251. 251. 251.  14.]]\n",
      "\n",
      "  [[150. 144. 151.  66.]\n",
      "   [150. 144. 151.  67.]\n",
      "   [150. 144. 151.  65.]\n",
      "   ...\n",
      "   [251. 251. 251.  10.]\n",
      "   [251. 251. 251.  13.]\n",
      "   [251. 251. 251.  14.]]]]\n"
     ]
    }
   ],
   "source": [
    "# Generate the frames and frame_diffs array for still\n",
    "still_frames, still_diff, still_labels = process_videos(default_paths, 0)\n",
    " # checking data of still_diff\n",
    "# for i, x in enumerate(still_diff):\n",
    "#     print(\" i= \"+str(i)+\" mean = \"+str(np.mean(x)))\n",
    "\n",
    "falling_frames, falling_diff, falling_labels = process_videos(falling_paths, 1)\n",
    "\n",
    "# checking data of still_diff\n",
    "# for i, x in enumerate(falling_diff):\n",
    "#     print(\" i= \"+str(i)+\" mean = \"+str(np.mean(x)))\n",
    "\n",
    "# Combine them\n",
    "concatenate_frames = np.concatenate([still_frames, falling_frames], axis = 0)\n",
    "# print(concatenate_frames.shape)\n",
    "concatenate_diff =  np.concatenate([still_diff, falling_diff], axis = 0)\n",
    "# print(concatenate_diff.shape)\n",
    "concatenate_labels =  np.concatenate([still_labels, falling_labels], axis = 0)\n",
    "# print(concatenate_labels.shape)\n",
    "\n",
    "# Create 224x224x4 shape for the model\n",
    "combined_input = combine_frames_and_diffs(concatenate_frames, concatenate_diff)\n",
    "# print(combined_input)\n",
    "print(combined_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [135. 135. 132.   0.]\n",
      "   ...\n",
      "   [119. 121. 116.   0.]\n",
      "   [120. 122. 117.   0.]\n",
      "   [120. 122. 117.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[186. 182. 174.   0.]\n",
      "   [195. 191. 183.   0.]\n",
      "   [198. 194. 186.   0.]\n",
      "   ...\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]]\n",
      "\n",
      "  [[191. 187. 179.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]\n",
      "\n",
      "  [[195. 191. 183.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]]\n",
      "\n",
      "\n",
      " [[[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   ...\n",
      "   [117. 119. 114.   0.]\n",
      "   [119. 121. 116.   0.]\n",
      "   [119. 121. 116.   0.]]\n",
      "\n",
      "  [[133. 133. 130.   0.]\n",
      "   [133. 133. 130.   0.]\n",
      "   [135. 135. 132.   0.]\n",
      "   ...\n",
      "   [119. 121. 116.   0.]\n",
      "   [120. 122. 117.   0.]\n",
      "   [120. 122. 117.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[186. 182. 174.   0.]\n",
      "   [195. 191. 183.   0.]\n",
      "   [198. 194. 186.   0.]\n",
      "   ...\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]\n",
      "   [146. 142. 134.   0.]]\n",
      "\n",
      "  [[191. 187. 179.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]\n",
      "\n",
      "  [[195. 191. 183.   0.]\n",
      "   [199. 195. 187.   0.]\n",
      "   [202. 198. 190.   0.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]]\n",
      "\n",
      "\n",
      " [[[125. 125. 122.   8.]\n",
      "   [128. 128. 125.   5.]\n",
      "   [131. 131. 128.   2.]\n",
      "   ...\n",
      "   [121. 126. 120.   6.]\n",
      "   [122. 127. 121.   7.]\n",
      "   [122. 127. 121.   5.]]\n",
      "\n",
      "  [[142. 142. 139.   9.]\n",
      "   [151. 151. 148.  18.]\n",
      "   [149. 149. 146.  16.]\n",
      "   ...\n",
      "   [121. 126. 120.   6.]\n",
      "   [122. 127. 121.   5.]\n",
      "   [122. 127. 121.   5.]]\n",
      "\n",
      "  [[187. 187. 184.  54.]\n",
      "   [220. 220. 217.  87.]\n",
      "   [224. 224. 221.  89.]\n",
      "   ...\n",
      "   [121. 126. 120.   4.]\n",
      "   [122. 127. 121.   4.]\n",
      "   [122. 127. 121.   4.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[209. 205. 197.  23.]\n",
      "   [213. 209. 201.  18.]\n",
      "   [217. 213. 205.  19.]\n",
      "   ...\n",
      "   [145. 141. 133.   1.]\n",
      "   [145. 141. 133.   1.]\n",
      "   [145. 141. 133.   1.]]\n",
      "\n",
      "  [[216. 212. 204.  25.]\n",
      "   [219. 215. 207.  20.]\n",
      "   [221. 217. 209.  19.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]\n",
      "\n",
      "  [[220. 216. 208.  25.]\n",
      "   [221. 217. 209.  22.]\n",
      "   [223. 219. 211.  21.]\n",
      "   ...\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]\n",
      "   [145. 141. 133.   0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 79.  78.  83.  14.]\n",
      "   [ 79.  78.  83.  15.]\n",
      "   [ 78.  77.  82.  15.]\n",
      "   ...\n",
      "   [252. 236. 253.   8.]\n",
      "   [251. 235. 250.  10.]\n",
      "   [250. 234. 249.  11.]]\n",
      "\n",
      "  [[ 79.  78.  83.  13.]\n",
      "   [ 79.  78.  83.  14.]\n",
      "   [ 78.  77.  82.  14.]\n",
      "   ...\n",
      "   [252. 236. 253.   8.]\n",
      "   [251. 235. 250.  10.]\n",
      "   [250. 234. 249.  11.]]\n",
      "\n",
      "  [[ 80.  79.  84.  15.]\n",
      "   [ 80.  79.  84.  16.]\n",
      "   [ 79.  78.  83.  16.]\n",
      "   ...\n",
      "   [252. 235. 255.   9.]\n",
      "   [251. 235. 252.   9.]\n",
      "   [250. 234. 251.  10.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83.  82.  87.  54.]\n",
      "   [ 82.  81.  86.  53.]\n",
      "   [ 81.  80.  85.  50.]\n",
      "   ...\n",
      "   [232. 248. 246.   2.]\n",
      "   [228. 246. 245.   5.]\n",
      "   [226. 244. 243.  12.]]\n",
      "\n",
      "  [[ 82.  81.  86.  54.]\n",
      "   [ 81.  80.  85.  53.]\n",
      "   [ 80.  79.  84.  49.]\n",
      "   ...\n",
      "   [231. 247. 245.   2.]\n",
      "   [224. 245. 243.  11.]\n",
      "   [223. 244. 242.  13.]]\n",
      "\n",
      "  [[ 81.  80.  85.  54.]\n",
      "   [ 80.  79.  84.  51.]\n",
      "   [ 82.  81.  86.  46.]\n",
      "   ...\n",
      "   [230. 246. 244.   5.]\n",
      "   [224. 245. 243.  12.]\n",
      "   [223. 244. 242.  13.]]]\n",
      "\n",
      "\n",
      " [[[ 79.  78.  83.   0.]\n",
      "   [ 79.  78.  83.   0.]\n",
      "   [ 78.  77.  82.   0.]\n",
      "   ...\n",
      "   [252. 236. 253.   0.]\n",
      "   [251. 235. 250.   0.]\n",
      "   [250. 234. 249.   0.]]\n",
      "\n",
      "  [[ 79.  78.  83.   0.]\n",
      "   [ 79.  78.  83.   0.]\n",
      "   [ 78.  77.  82.   0.]\n",
      "   ...\n",
      "   [252. 236. 253.   0.]\n",
      "   [251. 235. 250.   0.]\n",
      "   [250. 234. 249.   0.]]\n",
      "\n",
      "  [[ 80.  79.  84.   0.]\n",
      "   [ 80.  79.  84.   0.]\n",
      "   [ 79.  78.  83.   0.]\n",
      "   ...\n",
      "   [252. 235. 255.   0.]\n",
      "   [251. 235. 252.   0.]\n",
      "   [250. 234. 251.   0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83.  82.  87.   0.]\n",
      "   [ 82.  81.  86.   0.]\n",
      "   [ 81.  80.  85.   0.]\n",
      "   ...\n",
      "   [232. 248. 246.   0.]\n",
      "   [228. 246. 245.   0.]\n",
      "   [226. 244. 243.   0.]]\n",
      "\n",
      "  [[ 82.  81.  86.   0.]\n",
      "   [ 81.  80.  85.   0.]\n",
      "   [ 80.  79.  84.   0.]\n",
      "   ...\n",
      "   [231. 247. 245.   0.]\n",
      "   [224. 245. 243.   0.]\n",
      "   [223. 244. 242.   0.]]\n",
      "\n",
      "  [[ 81.  80.  85.   0.]\n",
      "   [ 80.  79.  84.   0.]\n",
      "   [ 82.  81.  86.   0.]\n",
      "   ...\n",
      "   [230. 246. 244.   0.]\n",
      "   [224. 245. 243.   0.]\n",
      "   [223. 244. 242.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 81.  80.  85.   2.]\n",
      "   [ 81.  80.  85.   2.]\n",
      "   [ 80.  79.  84.   2.]\n",
      "   ...\n",
      "   [239. 221. 255.  13.]\n",
      "   [239. 221. 255.  11.]\n",
      "   [241. 223. 255.   8.]]\n",
      "\n",
      "  [[ 83.  82.  87.   4.]\n",
      "   [ 82.  81.  86.   3.]\n",
      "   [ 81.  80.  85.   3.]\n",
      "   ...\n",
      "   [238. 220. 255.  14.]\n",
      "   [239. 221. 255.  11.]\n",
      "   [239. 221. 255.  10.]]\n",
      "\n",
      "  [[ 83.  82.  87.   3.]\n",
      "   [ 83.  82.  87.   3.]\n",
      "   [ 82.  81.  86.   3.]\n",
      "   ...\n",
      "   [238. 220. 255.  13.]\n",
      "   [238. 220. 255.  13.]\n",
      "   [239. 221. 255.  11.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[148. 142. 149.  62.]\n",
      "   [148. 142. 149.  63.]\n",
      "   [148. 142. 149.  64.]\n",
      "   ...\n",
      "   [251. 251. 251.   8.]\n",
      "   [251. 251. 251.  10.]\n",
      "   [251. 251. 251.  12.]]\n",
      "\n",
      "  [[150. 144. 151.  65.]\n",
      "   [150. 144. 151.  66.]\n",
      "   [150. 144. 151.  67.]\n",
      "   ...\n",
      "   [251. 251. 251.   9.]\n",
      "   [251. 251. 251.  13.]\n",
      "   [251. 251. 251.  14.]]\n",
      "\n",
      "  [[150. 144. 151.  66.]\n",
      "   [150. 144. 151.  67.]\n",
      "   [150. 144. 151.  65.]\n",
      "   ...\n",
      "   [251. 251. 251.  10.]\n",
      "   [251. 251. 251.  13.]\n",
      "   [251. 251. 251.  14.]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 14:41:35.944256: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 867041280 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Generate the frames and frame_diffs array for still\n",
    "still_frames, still_diff, still_labels = process_videos(default_paths, 0)\n",
    "# checking data of still_diff\n",
    "# for i, x in enumerate(still_diff):\n",
    "#     print(\" i= \"+str(i)+\" mean = \"+str(np.mean(x)))\n",
    "\n",
    "falling_frames, falling_diff, falling_labels = process_videos(falling_paths, 1)\n",
    "\n",
    "# checking data of still_diff\n",
    "# for i, x in enumerate(falling_diff):\n",
    "#     print(\" i= \"+str(i)+\" mean = \"+str(np.mean(x)))\n",
    "\n",
    "# Combine them\n",
    "concatenate_frames = np.concatenate([still_frames, falling_frames], axis = 0)\n",
    "# print(concatenate_frames.shape)\n",
    "concatenate_diff =  np.concatenate([still_diff, falling_diff], axis = 0)\n",
    "# print(concatenate_diff.shape)\n",
    "concatenate_labels =  np.concatenate([still_labels, falling_labels], axis = 0)\n",
    "# print(concatenate_labels.shape)\n",
    "\n",
    "# Create 224x224x4 shape for the model\n",
    "combined_input = combine_frames_and_diffs(concatenate_frames, concatenate_diff)\n",
    "# print(combined_input)\n",
    "print(combined_input)\n",
    "\n",
    "# Shuffle the data if needed\n",
    "indices = np.arange(combined_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "combined_input = combined_input[indices]\n",
    "concatenate_labels = concatenate_labels[indices]\n",
    "\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "with tf.device('/cpu:0'):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((combined_input, concatenate_labels))\n",
    "    dataset = dataset.batch(16).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Split the dataset into training and validation\n",
    "train_dataset = dataset.take(int(0.8 * len(dataset)))\n",
    "val_dataset = dataset.skip(int(0.8 * len(dataset)))\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((combined_input, concatenate_labels))\n",
    "# Batch and prefetch if needed\n",
    "# dataset = dataset.batch(16).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " combined_input (InputLayer)  [(None, 224, 224, 4)]    0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 222, 222, 32)      1184      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 26, 26, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               11075712  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,177,569\n",
      "Trainable params: 11,177,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    combined_input = Input(shape=(224, 224, 4), name='combined_input')\n",
    "\n",
    "    # Convolutional layers for image processing\n",
    "    # Convolutional layers are useful for learning spatial hierarchies and detecting features \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(combined_input) #  Convolutional layers extract spatial features from the image\n",
    "    x = MaxPooling2D((2, 2))(x) #  Max-pooling layers reduce the size of the feature maps.\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Fully connected layers: These layers learn to make decisions based on the features extracted by the convolutional layers\n",
    "    x = Flatten()(x) # This line flattens the 2D feature maps into a 1D vector\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)  # Single output with sigmoid activation\n",
    "\n",
    "    model = Model(inputs=combined_input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Binary cross-entropy loss\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "54/54 [==============================] - 3s 42ms/step - loss: 10.0360 - accuracy: 0.8021 - val_loss: 0.5283 - val_accuracy: 0.8843\n",
      "Epoch 2/8\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 0.1437 - accuracy: 0.9549 - val_loss: 0.0592 - val_accuracy: 0.9954\n",
      "Epoch 3/8\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 0.1487 - accuracy: 0.9803 - val_loss: 0.3073 - val_accuracy: 0.9444\n",
      "Epoch 4/8\n",
      "54/54 [==============================] - 2s 39ms/step - loss: 0.2109 - accuracy: 0.9502 - val_loss: 0.1213 - val_accuracy: 0.9630\n",
      "Epoch 5/8\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.0954 - accuracy: 0.9919 - val_loss: 0.0575 - val_accuracy: 0.9815\n",
      "Epoch 6/8\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 0.1810 - accuracy: 0.9769 - val_loss: 0.1157 - val_accuracy: 0.9722\n",
      "Epoch 7/8\n",
      "54/54 [==============================] - 2s 40ms/step - loss: 0.5238 - accuracy: 0.9676 - val_loss: 0.0658 - val_accuracy: 0.9861\n",
      "Epoch 8/8\n",
      "54/54 [==============================] - 2s 43ms/step - loss: 0.0580 - accuracy: 0.9919 - val_loss: 0.0555 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dc064ca60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n",
      "\n",
      "(1, 3, 3)\n",
      "[[[1 2 3]\n",
      "  [1 2 3]\n",
      "  [1 2 3]]]\n",
      "\n",
      "(3, 1, 3)\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[1 2 3]]\n",
      "\n",
      " [[1 2 3]]]\n",
      "\n",
      "(3, 3, 1)\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[1]\n",
      "  [2]\n",
      "  [3]]]\n"
     ]
    }
   ],
   "source": [
    "# Testing something not part of the main code\n",
    "arr1 = [[1,2,3], [1,2,3], [1,2,3]]\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "print(arr1)\n",
    "print()\n",
    "# exapand dims through axis 0\n",
    "arr1_expanded = np.expand_dims(arr1, axis = 0)\n",
    "print(arr1_expanded.shape)\n",
    "print(arr1_expanded)\n",
    "print()\n",
    "# exapand dims through axis 1\n",
    "arr2 = [[1,2,3], [1,2,3], [1,2,3]]\n",
    "arr2 = np.array(arr2)\n",
    "arr2_expanded = np.expand_dims(arr2, axis = 1)\n",
    "print(arr2_expanded.shape)\n",
    "print(arr2_expanded)\n",
    "print()\n",
    "arr3 = [[1,2,3], [1,2,3], [1,2,3]]\n",
    "arr3 = np.array(arr3)\n",
    "arr3_expanded = np.expand_dims(arr3, axis = -1)\n",
    "print(arr3_expanded.shape)\n",
    "print(arr3_expanded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
